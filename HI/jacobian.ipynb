{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6edbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a821f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside=256\n",
    "freqs=np.arange(544,1088,step=1)\n",
    "# nfreqs=len(freqs)\n",
    "nfreqs=181\n",
    "lmax=3*nside -1\n",
    "almsize=hp.Alm.getsize(lmax)\n",
    "r=3 #foreground model rank\n",
    "nbins=76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9634a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 181, 181)\n"
     ]
    }
   ],
   "source": [
    "noise_binned= np.load('noise_binned.npy')\n",
    "hi_binned= np.load('hi_binned.npy')\n",
    "c_hat=np.load('binned_empirical.npy')\n",
    "print(hi_binned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3c5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smica(params,hi, noise, empirical,  n_bins, nfreqs, r):\n",
    "    \n",
    "    # Reshape the flattened params back into F_init and P_b_init\n",
    "    \n",
    "    F = params[:nfreqs * r].reshape((nfreqs, r))\n",
    "    P_b = params[nfreqs * r:].reshape((n_bins,r,r))\n",
    "    \n",
    "    \n",
    "    \"\"\"# === Normalize columns of F and rescale P accordingly ===\n",
    "    for i in range(r):\n",
    "        norm = np.linalg.norm(F[:, i])\n",
    "\n",
    "        F[:, i] /= norm  # normalize column\n",
    "        for b in range(n_bins):\n",
    "            P_b[b, i, :] *= norm\n",
    "            P_b[b, :, i] *= norm  # symmetric scaling\"\"\"\n",
    "    \n",
    "    \n",
    "    # norm = np.linalg.norm(F, axis=0)\n",
    "    \n",
    "    # # Normalize F\n",
    "    # F_normalized = F / norm        \n",
    "    # # Adjust P_b: D^{-1} P_b D^{-1}\n",
    "    # D_inv = np.diag(1.0 / norm)\n",
    "    # for b in range(n_bins):\n",
    "    #     P_b[b] = D_inv @ P_b[b] @ D_inv\n",
    "                \n",
    "    # === Compute the cost function ===            \n",
    "    cost=0\n",
    "    model=np.zeros((n_bins, nfreqs, nfreqs))\n",
    "    model_inv=np.zeros((n_bins, nfreqs, nfreqs))\n",
    "    \n",
    "    # term=np.zeros(n_bins)\n",
    "    for b in range(n_bins):\n",
    "        model[b]= hi[b] + noise[b] + np.dot(F, np.dot(P_b[b], F.T))\n",
    "        model_inv[b]= np.linalg.inv(model[b])\n",
    "        \n",
    "        sign, logdet= np.linalg.slogdet(np.dot(empirical[b],model_inv[b]))\n",
    "        trace=np.trace(np.dot(empirical[b] , model_inv[b]))\n",
    "        \n",
    "        term = logdet + trace -nfreqs\n",
    "        cost += term\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4741ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_2(params,hi, noise,  empirical, n_bins, nfreqs, r):\n",
    "    \n",
    "    delta_ell=10\n",
    "    # Reshape the flattened params back into F_init and P_b_init\n",
    "    F = params[:nfreqs * r].reshape((nfreqs, r))\n",
    "    P_b = params[nfreqs * r:].reshape((n_bins,r,r))\n",
    "    \n",
    "    \"\"\"# === Normalize columns of F and rescale P accordingly ===\n",
    "    for i in range(r):\n",
    "        norm = np.linalg.norm(F[:, i])\n",
    "        \n",
    "        F[:, i] /= norm  # normalize column\n",
    "        for b in range(n_bins):\n",
    "            # Scale row i and column i of P_b[b] accordingly\n",
    "            P_b[b, i, :] *= norm\n",
    "            P_b[b, :, i] *= norm \"\"\"\n",
    "            \n",
    "    # Compute norms of each column of F\n",
    "    # norm = np.linalg.norm(F, axis=0)\n",
    "    \n",
    "    # # Normalize F\n",
    "    # F_normalized = F / norm        \n",
    "    # # Adjust P_b: D^{-1} P_b D^{-1}\n",
    "    # D_inv = np.diag(1.0 / norm)\n",
    "    # for b in range(n_bins):\n",
    "    #     P_b[b] = D_inv @ P_b[b] @ D_inv\n",
    "    \n",
    "    grad_P=np.zeros_like(P_b) # Derivative wrt P_b\n",
    "    grad_F=np.zeros_like(F) # Derivative wrt F\n",
    "    \n",
    "    for b in range(n_bins):\n",
    "        \n",
    "        R= np.dot(F, np.dot(P_b[b], F.T)) # model covariance depending on only unknown parameters\n",
    "        \"\"\"try:\n",
    "            R_inv = np.linalg.inv(R)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Optional: add small regularization to make model invertible\n",
    "            R += 1e-6 * np.identity(nfreqs)\n",
    "            R_inv = np.linalg.inv(R)\"\"\"\n",
    "        R_inv= np.linalg.inv(R)\n",
    "        \n",
    "        Delta= R_inv - np.dot(R_inv,np.dot(empirical[b], R_inv)) #nf x nf\n",
    "\n",
    "        # ∂φ/∂P_q \n",
    "        grad_P[b,:,:]= np.dot(F.T, np.dot(Delta, F)) # (r,r)\n",
    "        # ∂φ/∂F\n",
    "        grad_F += 2*np.dot(Delta, np.dot(F, P_b[b])) # (nf,r)\n",
    "        \n",
    "    # Flatten the gradients\n",
    "    grad_P_flat = grad_P.flatten()\n",
    "    grad_F_flat = grad_F.flatten()\n",
    "    print(grad_F_flat.shape)\n",
    "    print(grad_P_flat.shape)\n",
    "    grad_total= np.concatenate([grad_F_flat.flatten(), grad_P_flat.flatten()])\n",
    "    return grad_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670a458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(empirical, r, n_bins):\n",
    "    \"\"\"\n",
    "    Perform PCA on the covariance matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    c_hat : np.ndarray\n",
    "        Covariance matrix of shape (n_bins, n_freq, n_freq).\n",
    "    \n",
    "    r : int\n",
    "        Number of principal components to retain.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    F : np.ndarray\n",
    "        Matrix of shape (n_freq, r) containing the principal components.\n",
    "    \n",
    "    P_b : np.ndarray\n",
    "        Matrix of shape (n_bins, r, r) containing the eigenvalues and eigenvectors.\n",
    "    \"\"\"\n",
    "    # Perform PCA\n",
    "    R_global = np.mean(empirical, axis=0)  # c_hat has shape (n_bins, n_freqs, n_freqs)\n",
    "    #eigen decompositiom\n",
    "    eigvals, eigvecs = np.linalg.eigh(R_global) #ascending order\n",
    "    #Take the top r eigenvectors:\n",
    "    F = eigvecs[:, -r:]  # largest eigenvectors\n",
    "\n",
    "    P_b = np.zeros((n_bins, r, r))\n",
    "    for b in range(n_bins):\n",
    "        P_b[b] =np.dot( F.T , np.dot(empirical[b] , F))\n",
    "        P_b[b] = 0.5 * (P_b[b] + P_b[b].T)\n",
    "    return eigvals,F, P_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664304f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e,F_pca, P_b_pca = pca(c_hat,r, nbins)\n",
    "params_pca = np.concatenate([F_pca.flatten(), P_b_pca.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac43690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 3)\n",
      "(76, 3, 3)\n",
      "(1227,)\n"
     ]
    }
   ],
   "source": [
    "print(F_pca.shape) \n",
    "print(P_b_pca.shape)\n",
    "print(params_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c2c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1707.294929961676\n"
     ]
    }
   ],
   "source": [
    "phi= smica(params_pca, hi_binned, noise_binned, c_hat, nbins, nfreqs, r)\n",
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b9aba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543,)\n",
      "(684,)\n",
      "[-1.62485676e+21 -3.88069569e+21 -8.56872485e+21 ... -7.64948241e+21\n",
      "  4.05848519e+21  1.03084668e+22]\n",
      "(1227,)\n"
     ]
    }
   ],
   "source": [
    "Grad= jacobian_2(params_pca, hi_binned, noise_binned, c_hat, nbins, nfreqs, r)\n",
    "print(Grad)\n",
    "print(Grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cb8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: smica(x,hi=hi_binned, noise=noise_binned, empirical=c_hat, n_bins=nbins, nfreqs=nfreqs, r=r)\n",
    "grad_f = lambda x: jacobian_2(x,hi=hi_binned, noise=noise_binned, empirical=c_hat, n_bins=nbins, nfreqs=nfreqs, r=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3acf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_test(cost, grad_cost, params, epsilons=None):\n",
    "    if epsilons is None:\n",
    "        epsilons = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5] #stepsize\n",
    "\n",
    "    np.random.seed(0)\n",
    "    h = np.random.randn(*params.shape)\n",
    "    h /= np.linalg.norm(h)  #unit vector\n",
    "\n",
    "    f0 = cost(params) #at a point x0\n",
    "    grad0 = grad_cost(params) \n",
    "    directional_derivative = np.dot(grad0.T, h)\n",
    "\n",
    "    for eps in epsilons:\n",
    "        f_eps = cost(params + eps * h)\n",
    "        residual = abs(f_eps - f0 - eps * directional_derivative)\n",
    "        print(f\"epsilon = {eps:.1e}, Residual = {residual:.2e}, Residual/epsilon = {residual/eps:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c02d85f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jacobian_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtaylor_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_pca\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#3mins\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mtaylor_test\u001b[0;34m(cost, grad_cost, params, epsilons)\u001b[0m\n\u001b[1;32m      7\u001b[0m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(h)  \u001b[38;5;66;03m#unit vector\u001b[39;00m\n\u001b[1;32m      9\u001b[0m f0 \u001b[38;5;241m=\u001b[39m cost(params) \u001b[38;5;66;03m#at a point x0\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m grad0 \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m directional_derivative \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(grad0\u001b[38;5;241m.\u001b[39mT, h)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilons:\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: smica(x,hi\u001b[38;5;241m=\u001b[39mhi_binned, noise\u001b[38;5;241m=\u001b[39mnoise_binned, empirical\u001b[38;5;241m=\u001b[39mc_hat, n_bins\u001b[38;5;241m=\u001b[39mnbins, nfreqs\u001b[38;5;241m=\u001b[39mnfreqs, r\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m----> 2\u001b[0m grad_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mjacobian_2\u001b[49m(x,hi\u001b[38;5;241m=\u001b[39mhi_binned, noise\u001b[38;5;241m=\u001b[39mnoise_binned, empirical\u001b[38;5;241m=\u001b[39mc_hat, n_bins\u001b[38;5;241m=\u001b[39mnbins, nfreqs\u001b[38;5;241m=\u001b[39mnfreqs, r\u001b[38;5;241m=\u001b[39mr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jacobian_2' is not defined"
     ]
    }
   ],
   "source": [
    "taylor_test(f, grad_f, params_pca) #3mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "approx_grad = approx_fprime(params_pca, f, epsilon=1e-6) #finite differences\n",
    "print(approx_grad) #4mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae364ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_f1 = lambda x: approx_fprime(x, f, epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f16017",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtaylor_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_f1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_pca\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtaylor_test\u001b[0;34m(cost, grad_cost, params, epsilons)\u001b[0m\n\u001b[1;32m      7\u001b[0m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(h)  \u001b[38;5;66;03m#unit vector\u001b[39;00m\n\u001b[1;32m      9\u001b[0m f0 \u001b[38;5;241m=\u001b[39m cost(params) \u001b[38;5;66;03m#at a point x0\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m grad0 \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m directional_derivative \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(grad0\u001b[38;5;241m.\u001b[39mT, h)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilons:\n",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grad_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mapprox_fprime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:1030\u001b[0m, in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m   1027\u001b[0m xk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(xk, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m   1028\u001b[0m f0 \u001b[38;5;241m=\u001b[39m f(xk, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2-point\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                         \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf0\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:523\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:596\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    594\u001b[0m     x1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h[i]\n\u001b[1;32m    595\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x1[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    598\u001b[0m     x1[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h[i]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:474\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    472\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 474\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msmica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mempirical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m grad_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: jacobian_2(x,hi\u001b[38;5;241m=\u001b[39mhi_binned, noise\u001b[38;5;241m=\u001b[39mnoise_binned, empirical\u001b[38;5;241m=\u001b[39mc_hat, n_bins\u001b[38;5;241m=\u001b[39mnbins, nfreqs\u001b[38;5;241m=\u001b[39mnfreqs, r\u001b[38;5;241m=\u001b[39mr)\n",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m, in \u001b[0;36msmica\u001b[0;34m(params, hi, noise, empirical, n_bins, nfreqs, r)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_bins):\n\u001b[1;32m     35\u001b[0m     model[b]\u001b[38;5;241m=\u001b[39m hi[b] \u001b[38;5;241m+\u001b[39m noise[b] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(F, np\u001b[38;5;241m.\u001b[39mdot(P_b[b], F\u001b[38;5;241m.\u001b[39mT))\n\u001b[0;32m---> 36\u001b[0m     model_inv[b]\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     sign, logdet\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mslogdet(np\u001b[38;5;241m.\u001b[39mdot(empirical[b],model_inv[b]))\n\u001b[1;32m     39\u001b[0m     trace\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtrace(np\u001b[38;5;241m.\u001b[39mdot(empirical[b] , model_inv[b]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/_linalg.py:609\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    606\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_singular, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    608\u001b[0m               over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 609\u001b[0m     ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "taylor_test(f, grad_f1, params_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff49e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543,)\n",
      "(684,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(9.051665227619901e+25)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(approx_grad - grad_f(params_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b28482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_ff=np.load('smoothed_maps_1_nohi.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
